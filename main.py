# # Hierarchical Text Summarization with LLM
#
# –ü—Ä–æ–µ–∫—Ç –¥–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–Ω–∏–≥) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö LLM
# –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ llama.cpp. –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏, —Å–æ–∑–¥–∞–µ—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏,
# –∞ –∑–∞—Ç–µ–º —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö –≤ —Å–≤—è–∑–Ω–æ–µ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ.

import os
import re
import time
from llama_cpp import Llama
from typing import List

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–∑–∞–º–µ–Ω–∏ –Ω–∞ —Å–≤–æ–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏)
model_path = r"G:\LLM_models2\Grok-3-reasoning-gemma3-12B-distilled-HF.Q8_0.gguf"
llm = Llama(
    model_path=model_path,
    chat_format="gemma",  # –ò–ª–∏ –ø–æ–ø—Ä–æ–±—É–π "chatml" –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    n_ctx=32768,
    n_threads=8,
    n_gpu_layers=47,
    temperature=0.1,
    max_tokens=8192,
    verbose=True
)


def clean_model_output(text):
    """
    –û—á–∏—Å—Ç–∫–∞ –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏ –æ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ç–µ–≥–æ–≤.
    """
    # –£–¥–∞–ª—è–µ–º –±–ª–æ–∫–∏ <think>...</think>
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

    # –£–¥–∞–ª—è–µ–º –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ç–µ–≥–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
    text = re.sub(r'<reasoning>.*?</reasoning>', '', text, flags=re.DOTALL)
    text = re.sub(r'<reflection>.*?</reflection>', '', text, flags=re.DOTALL)
    text = re.sub(r'<scratchpad>.*?</scratchpad>', '', text, flags=re.DOTALL)

    # –£–¥–∞–ª—è–µ–º —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "Let me think", "Ok" –∏ —Ç.–¥.
    thinking_patterns = [
        r'Ok, let me think.*?\n\n',
        r'Let me see.*?\n\n',
        r'Let me figure this out.*?\n\n',
        r'First,.*?\n\n',
        r'I need to.*?\n\n',
        r'So,.*?\n\n',
        r'Alright,.*?\n\n',
        r'Okay,.*?\n\n',
    ]

    for pattern in thinking_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)

    return text.strip()


def combine_into_narrative(llm, text_list: List[str]) -> str:
    """
    –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å LLM –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏—Ö –≤ –æ–¥–Ω–æ —Å–≤—è–∑–Ω–æ–µ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ.

    :param llm: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Llama (–Ω–∞–ø—Ä–∏–º–µ—Ä, llm = Llama(...))
    :param text_list: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    :return: –û–¥–∏–Ω —Ç–µ–∫—Å—Ç, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–π –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
    """
    if not text_list:
        return ""

    system_message = {"role": "system",
                      "content": """–¢—ã ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–æ–≤.
                                 –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ.
                                 –í–ê–ñ–ù–û: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
                                 –ü—Ä–æ—Å—Ç–æ –¥–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""}

    cont_list = "".join(text_list)
    print(f"\n##########\n–°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ join \n{cont_list[:500]}...")

    messages = [
        system_message,
        {"role": "user", "content": f"""–°–æ–µ–¥–∏–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∏–∑ –ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –µ–¥–∏–Ω–æ–µ —Å–≤—è–∑–Ω–æ–µ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
            –û–±–µ—Å–ø–µ—á—å, —á—Ç–æ–±—ã –¥–ª–∏–Ω–∞ –≤—ã–≤–æ–¥–∞ –±—ã–ª–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–∞–∫–æ–π –∂–µ, –∫–∞–∫ –¥–ª–∏–Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.
            –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
            –ü—Ä–æ—Å—Ç–æ –¥–∞–π —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
            –ö–æ–Ω—Ç–µ–∫—Å—Ç: \n\n{cont_list}"""
         }
    ]

    response = llm.create_chat_completion(
        messages=messages,
        max_tokens=8000,
        temperature=0.1,
        stop=["</s>", "Human:", "<think>", "<reasoning>", "<scratchpad>"]
    )

    if response['choices']:
        result = response['choices'][0]['message']['content'].strip()
        # –û—á–∏—â–∞–µ–º –≤—ã–≤–æ–¥ –æ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
        result = clean_model_output(result)
        return result
    else:
        return ""


def clean_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    text = re.sub(r'\s+', ' ', text)  # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    text = re.sub(r'[^\w\s.,!?‚Äî‚Äì-]', '', text)  # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∫—Ä–æ–º–µ –±–∞–∑–æ–≤—ã—Ö
    return text.strip()


def chunk_text(text, chunk_size=500, overlap_sentences=3):
    """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ –ø—Ä–∏–º–µ—Ä–Ω–æ chunk_size —Å–∏–º–≤–æ–ª–æ–≤ —Å –Ω–∞—Ö–ª–µ—Å—Ç–æ–º –≤ overlap_sentences –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π."""
    sentences = re.split(r'(?<=[.!?])\s+', text)
    chunks = []
    current_chunk_sentences = []
    current_length = 0
    overlap = []

    for sentence in sentences:
        if overlap:
            current_chunk_sentences.extend(overlap)
            current_length += sum(len(s) + 1 for s in overlap)
            overlap = []

        current_chunk_sentences.append(sentence)
        current_length += len(sentence) + 1

        if current_length >= chunk_size:
            chunk_text_str = ' '.join(current_chunk_sentences)
            chunks.append(chunk_text_str)
            if len(current_chunk_sentences) >= overlap_sentences:
                overlap = current_chunk_sentences[-overlap_sentences:]
            else:
                overlap = current_chunk_sentences[:]
            current_chunk_sentences = []
            current_length = 0

    if current_chunk_sentences:
        chunks.append(' '.join(current_chunk_sentences))

    return chunks


def summarize_chunk(chunk, level=1, summary_file=None):
    """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞."""
    system_message = {"role": "system",
                      "content": """–¢—ã ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–∞–≤–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. 
                                 –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –§—Ä–∞–≥–º–µ–Ω—Ç –Ω–∏–∂–µ.
                                 –í–ê–ñ–ù–û: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
                                 –ù–µ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ –º—ã—Å–ª–∏. –ü—Ä–æ—Å—Ç–æ –¥–∞–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""}

    prompt = f"""–°—É–º–º–∏—Ä—É–π —ç—Ç–æ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –≤ 5-6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö, –≤–∫–ª—é—á–∞—è —Å—é–∂–µ—Ç, –∫–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è, –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –¥–∏–∞–ª–æ–≥–∏ –∏ —Ç–µ–º—ã. 
    –§—Ä–∞–≥–º–µ–Ω—Ç: {chunk}

    –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫—Ä–∞—Ç–∫–æ–π, –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—é–∂–µ—Ç, –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏, —Å–æ–±—ã—Ç–∏—è –∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π. 
    –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {level} (1 - —Å–∞–º—ã–π –¥–µ—Ç–∞–ª—å–Ω—ã–π, –≤—ã—à–µ - –±–æ–ª–µ–µ –æ–±–æ–±—â—ë–Ω–Ω—ã–π). 
    –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï, –±–µ–∑ –≤–≤–µ–¥–µ–Ω–∏—è –∏–ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è. 
    –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
    –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∏–∂–µ."""

    messages = [
        system_message,
        {"role": "user", "content": prompt}
    ]

    response = llm.create_chat_completion(
        messages=messages,
        max_tokens=600,
        temperature=0.1,
        stop=["</s>", "Human:", "<think>", "<reasoning>", "<scratchpad>", "Ok", "So,", "First,"]
    )

    summary = response['choices'][0]['message']['content'].strip()

    # –û—á–∏—â–∞–µ–º –≤—ã–≤–æ–¥ –æ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
    summary = clean_model_output(summary)

    # –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π
    if summary_file:
        summary_file.write(f"\n{'=' * 80}\n")
        summary_file.write(f"–ß–ê–ù–ö (—É—Ä–æ–≤–µ–Ω—å {level}):\n")
        summary_file.write(f"{chunk[:500]}...\n\n" if len(chunk) > 500 else f"{chunk}\n\n")
        summary_file.write(f"–°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø –ß–ê–ù–ö–ê:\n")
        summary_file.write(f"{summary}\n")
        summary_file.write(f"{'=' * 80}\n\n")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫
    english_words = ['the', 'and', 'of', 'to', 'a', 'in', 'that', 'it', 'with', 'as', 'for']
    word_count = len(summary.split())

    if word_count > 10:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π
        english_word_count = sum(1 for word in english_words if word in summary.lower().split())
        if english_word_count > 2:  # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª—å—à–µ 2 –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤
            print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –≤ —Å–≤–æ–¥–∫–µ —á–∞–Ω–∫–∞. –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É—é...")
            if summary_file:
                summary_file.write("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –≤ —Å–≤–æ–¥–∫–µ —á–∞–Ω–∫–∞. –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É—é...\n")

            # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            strict_prompt = f"""–ü–µ—Ä–µ–ø–∏—à–∏ —ç—Ç—É —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:
            –ò—Å—Ö–æ–¥–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è: {summary}

            –ü–µ—Ä–µ–ø–∏—à–∏ –Ω–∞ —á–∏—Å—Ç–æ–º —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –±–µ–∑ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤. 
            –°–¥–µ–ª–∞–π 5-6 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ —Å—é–∂–µ—Ç–µ, —Å–æ–±—ã—Ç–∏—è—Ö –∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞—Ö.
            –¢–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫!"""

            strict_messages = [
                system_message,
                {"role": "user", "content": strict_prompt}
            ]

            response = llm.create_chat_completion(
                messages=strict_messages,
                max_tokens=600,
                temperature=0.3,
                stop=["</s>", "Human:", "<think>"]
            )

            summary = response['choices'][0]['message']['content'].strip()
            summary = clean_model_output(summary)

            if summary_file:
                summary_file.write(f"–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø:\n{summary}\n\n")

    print(summary[:200] + "..." if len(summary) > 200 else summary)
    return summary


def hierarchical_summarize(summaries, max_group_size=5, level=1, summary_file=None, log_file=None):
    """–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å —Ä–µ–∫—É—Ä—Å–∏–µ–π."""
    if log_file:
        log_file.write(f"=== –£—Ä–æ–≤–µ–Ω—å {level}: –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(summaries)} —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π ===\n")
        for idx, summ in enumerate(summaries):
            log_file.write(f"–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {idx + 1}: {summ[:100]}...\n")
        log_file.write("\n")

    if len(summaries) <= 1:
        if log_file:
            log_file.write(f"–£—Ä–æ–≤–µ–Ω—å {level}: –ú–∞–ª–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å.\n\n")
        return summaries[0] if summaries else ""

    if len(summaries) <= max_group_size:
        combined = "\n\n".join(summaries)

        system_message = {"role": "system",
                          "content": """–¢—ã ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–∞–≤–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. 
                                     –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π. 
                                     –í–ê–ñ–ù–û: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
                                     –ù–µ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ –º—ã—Å–ª–∏. –ü—Ä–æ—Å—Ç–æ –¥–∞–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é."""}

        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –¢–û–õ–¨–ö–û —ç—Ç–∏—Ö –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π, —Å–æ–∑–¥–∞–π –±–æ–ª–µ–µ –æ–±–æ–±—â—ë–Ω–Ω—É—é —Å–≤–æ–¥–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. 
        –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {combined}

        –°–≤–æ–¥–∫–∞ –¥–æ–ª–∂–Ω–∞ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å—é–∂–µ—Ç, –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—é–∂–µ—Ç–∞. 
        –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {level}. 
        –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï, –≤ 5-8 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö.
        –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è."""

        messages = [
            system_message,
            {"role": "user", "content": prompt}
        ]

        response = llm.create_chat_completion(
            messages=messages,
            max_tokens=800,
            temperature=0.1,
            stop=["</s>", "Human:", "<think>", "<reasoning>"]
        )

        super_summary = response['choices'][0]['message']['content'].strip()
        super_summary = clean_model_output(super_summary)

        # –ó–∞–ø–∏—Å—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª
        if summary_file:
            summary_file.write(f"\n{'#' * 80}\n")
            summary_file.write(f"–ò–ï–†–ê–†–•–ò–ß–ï–°–ö–ê–Ø –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø (—É—Ä–æ–≤–µ–Ω—å {level}):\n")
            summary_file.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π: {len(summaries)}\n")
            summary_file.write(f"–†–µ–∑—É–ª—å—Ç–∞—Ç:\n{super_summary}\n")
            summary_file.write(f"{'#' * 80}\n\n")

        if log_file:
            log_file.write(
                f"–£—Ä–æ–≤–µ–Ω—å {level}: –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ –∏–∑ {len(summaries)} –≤ —Å—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é: {super_summary[:200]}...\n\n")

        print(f"–£—Ä–æ–≤–µ–Ω—å {level}: {super_summary[:200]}...")
        return super_summary

    # –†–µ–∫—É—Ä—Å–∏—è: —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –≥—Ä—É–ø–ø—ã
    groups = [summaries[i:i + max_group_size] for i in range(0, len(summaries), max_group_size)]

    if log_file:
        log_file.write(f"\n–£—Ä–æ–≤–µ–Ω—å {level}: –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(groups)} –≥—Ä—É–ø–ø –ø–æ {max_group_size}.\n")
        for g_idx, group in enumerate(groups):
            log_file.write(f"  –ì—Ä—É–ø–ø–∞ {g_idx + 1}: {len(group)} —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π\n")
        log_file.write("\n")

    super_summaries = []

    for group in groups:
        super_summary = hierarchical_summarize(group, max_group_size, level + 1, summary_file, log_file)
        super_summaries.append(super_summary)

        if log_file:
            log_file.write(f"–£—Ä–æ–≤–µ–Ω—å {level}: –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≥—Ä—É–ø–ø—ã: {super_summary[:200]}...\n")
            log_file.write(f"\n–ò—Ç–æ–≥–æ –ø–æ –≥—Ä—É–ø–ø–µ super_summaries: {len(super_summaries)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n")

        print(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è: {super_summary[:100]}...")

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π –≤ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
    comb = combine_into_narrative(llm, super_summaries)

    if summary_file:
        summary_file.write(f"\n{'@' * 80}\n")
        summary_file.write(f"–û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –°–£–ü–ï–†-–°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ô (—É—Ä–æ–≤–µ–Ω—å {level}):\n")
        summary_file.write(f"–ò—Å—Ö–æ–¥–Ω—ã–µ —Å—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {len(super_summaries)}\n")
        for i, summ in enumerate(super_summaries):
            summary_file.write(f"\n–°—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {i + 1}:\n{summ[:300]}...\n" if len(
                summ) > 300 else f"\n–°—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {i + 1}:\n{summ}\n")
        summary_file.write(f"\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ):\n{comb}\n")
        summary_file.write(f"{'@' * 80}\n\n")

    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º —Å—É–ø–µ—Ä-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
    final = hierarchical_summarize(super_summaries, max_group_size, level, summary_file, log_file)
    final = clean_model_output(final)

    if log_file:
        log_file.write(f"–£—Ä–æ–≤–µ–Ω—å {level}: –§–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å—É–ø–µ—Ä-–≥—Ä—É–ø–ø –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n\n")
        log_file.write(f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è: {final[:500]}...\n")

    return final


def main():
    # –ù–∞—á–∞–ª–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
    start_time = time.time()

    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–ø–∏—Å–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    summary_output_file = "Summary_Detailed.txt"
    final_output_file = "Output_summary.txt"
    log_file_path = "hierarchical_log.txt"

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–ø–∏—Å–∏
    summary_file = open(summary_output_file, 'w', encoding='utf-8')
    final_file = open(final_output_file, 'w', encoding='utf-8')
    log_file = open(log_file_path, "w", encoding="utf-8")

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤
    summary_file.write("=" * 100 + "\n")
    summary_file.write("–ü–û–î–†–û–ë–ù–ê–Ø –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø –¢–ï–ö–°–¢–ê\n")
    summary_file.write("=" * 100 + "\n\n")

    final_file.write("=" * 100 + "\n")
    final_file.write("–ò–¢–û–ì–û–í–ê–Ø –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–Ø –¢–ï–ö–°–¢–ê\n")
    final_file.write("–í–°–ï –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ò –¢–ï–ì–ò –£–î–ê–õ–ï–ù–´\n")
    final_file.write("=" * 100 + "\n\n")

    log_file.write("–õ–æ–≥ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏\n\n")

    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∫–Ω–∏–≥–æ–π
    book_file = r"G:\books\Master_i_Margarita.txt"

    if not os.path.exists(book_file):
        print(f"‚ùå –§–∞–π–ª {book_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        summary_file.close()
        final_file.close()
        log_file.close()
        return

    try:
        with open(book_file, 'r', encoding='cp1251') as book_f:
            full_text = book_f.read()
    except UnicodeDecodeError:
        with open(book_file, 'r', encoding='utf-8') as book_f:
            full_text = book_f.read()

    full_text = clean_text(full_text)
    print(f"üìñ –¢–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤.")
    summary_file.write(f"üìñ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤.\n\n")

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
    chunks = chunk_text(full_text, chunk_size=3000)
    print(f"üî¢ –¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª—ë–Ω –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤.")
    summary_file.write(f"üî¢ –¢–µ–∫—Å—Ç —Ä–∞–∑–¥–µ–ª—ë–Ω –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤.\n\n")

    # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —á–∞–Ω–∫–æ–≤
    summaries = []
    for i, chunk in enumerate(chunks):
        print(f"–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É—é —á–∞–Ω–∫ {i + 1}/{len(chunks)}...")
        summary_file.write(f"\n{'=' * 80}\n")
        summary_file.write(f"–û–ë–†–ê–ë–û–¢–ö–ê –ß–ê–ù–ö–ê {i + 1} –∏–∑ {len(chunks)}\n")
        summary_file.write(f"{'=' * 80}\n")

        summary = summarize_chunk(chunk, level=1, summary_file=summary_file)
        summaries.append(summary)
        print(f"‚úÖ –ß–∞–Ω–∫ {i + 1} –≥–æ—Ç–æ–≤: {len(summary)} —Å–∏–º–≤–æ–ª–æ–≤.")

    # –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
    print("üèóÔ∏è –ù–∞—á–∏–Ω–∞—é –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é...")
    summary_file.write("\n\n" + "=" * 100 + "\n")
    summary_file.write("–ù–ê–ß–ê–õ–û –ò–ï–†–ê–†–•–ò–ß–ï–°–ö–û–ô –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò\n")
    summary_file.write("=" * 100 + "\n\n")

    final_summary = hierarchical_summarize(summaries, summary_file=summary_file, log_file=log_file)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—â–∞—è —Å–≤–æ–¥–∫–∞
    print("üìù –°–æ–∑–¥–∞—é —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ–±—â—É—é —Å–≤–æ–¥–∫—É...")
    system_message = {"role": "system",
                      "content": """–¢—ã ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–∞–≤–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. 
                                 –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π. 
                                 –í–ê–ñ–ù–û: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.
                                 –ù–µ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ –º—ã—Å–ª–∏. –ü—Ä–æ—Å—Ç–æ –¥–∞–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é."""}

    final_prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –¢–û–õ–¨–ö–û –≠–¢–û–ô –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–π —Å–≤–æ–¥–∫–∏, —Å–æ–∑–¥–∞–π –ø–æ–ª–Ω—É—é –æ–±—â—É—é —Å–≤–æ–¥–∫—É –≤ 10-20 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. 
    –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å–≤–æ–¥–∫–∞: {final_summary}

    –°–≤–æ–¥–∫–∞ –¥–æ–ª–∂–Ω–∞ –æ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å —Å—é–∂–µ—Ç, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã, –∫–ª—é—á–µ–≤—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏ —Å—é–∂–µ—Ç–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã. 
    –ò–∑ –æ–±—â–µ–π —Å–≤–æ–¥–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã —Å—é–∂–µ—Ç, —Å—é–∂–µ—Ç–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã –∏ –∫–ª—é—á–µ–≤—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏. 
    –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.
    –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <think>, <reasoning> –∏–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–∞-—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è."""

    messages = [
        system_message,
        {"role": "user", "content": final_prompt}
    ]

    response = llm.create_chat_completion(
        messages=messages,
        max_tokens=1600,
        temperature=0.1,
        stop=["</s>", "Human:", "<think>", "<reasoning>", "Ok,", "So,", "First,"]
    )

    overall_summary = response['choices'][0]['message']['content'].strip()
    overall_summary = clean_model_output(overall_summary)

    # –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ final_file (–∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª)
    final_file.write("=== –û–ë–©–ê–Ø –°–í–û–î–ö–ê (–û–ß–ò–©–ï–ù–ê –û–¢ –†–ê–°–°–£–ñ–î–ï–ù–ò–ô) ===\n\n")
    final_file.write(overall_summary)
    final_file.write("\n\n" + "=" * 80 + "\n\n")

    final_file.write("=== –ò–ï–†–ê–†–•–ò–ß–ï–°–ö–ê–Ø –°–í–û–î–ö–ê (–û–ß–ò–©–ï–ù–ê –û–¢ –†–ê–°–°–£–ñ–î–ï–ù–ò–ô) ===\n\n")
    final_file.write(final_summary)
    final_file.write("\n\n" + "=" * 80 + "\n\n")

    final_file.write("=== –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ï –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò –ß–ê–ù–ö–û–í ===\n")
    for i, summ in enumerate(summaries):
        final_file.write(f"\n{'=' * 60}\n")
        final_file.write(f"–ß–∞–Ω–∫ {i + 1}:\n")
        cleaned_summ = clean_model_output(summ)
        final_file.write(f"{cleaned_summ}\n")

    # –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ summary_file (–ø–æ–¥—Ä–æ–±–Ω—ã–π —Ñ–∞–π–ª)
    summary_file.write("\n\n" + "*" * 100 + "\n")
    summary_file.write("–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´\n")
    summary_file.write("*" * 100 + "\n\n")

    summary_file.write("=== –ò–¢–û–ì–û–í–ê–Ø –û–ë–©–ê–Ø –°–í–û–î–ö–ê (–û–ß–ò–©–ï–ù–ê) ===\n\n")
    summary_file.write(overall_summary)
    summary_file.write("\n\n" + "=" * 80 + "\n\n")

    summary_file.write("=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ò–ï–†–ê–†–•–ò–ß–ï–°–ö–ê–Ø –°–í–û–î–ö–ê (–û–ß–ò–©–ï–ù–ê) ===\n\n")
    summary_file.write(final_summary)

    print(f"üéâ –°–≤–æ–¥–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {final_output_file}")
    print(f"üìã –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {summary_output_file}")
    print(f"üìù –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {log_file_path}")

    print("\n--- –ü—Ä–µ–≤—å—é —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å–≤–æ–¥–∫–∏ ---")
    print(overall_summary[:500] + "..." if len(overall_summary) > 500 else overall_summary)

    # –ö–æ–Ω–µ—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∏ –≤—ã–≤–æ–¥
    end_time = time.time()
    elapsed = end_time - start_time
    elapsed_hours = elapsed / 3600

    print(f"\n–í—Ä–µ–º—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã: {elapsed:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed_hours:.2f} —á–∞—Å–æ–≤).")

    # –ó–∞–ø–∏—Å—å –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ñ–∞–π–ª—ã
    time_info = f"\n\n–í—Ä–µ–º—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã: {elapsed:.2f} —Å–µ–∫—É–Ω–¥ ({elapsed_hours:.2f} —á–∞—Å–æ–≤)."
    final_file.write(time_info)
    summary_file.write(time_info)
    log_file.write(time_info)

    # –ó–∞–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–æ–≤
    summary_file.close()
    final_file.close()
    log_file.close()


if __name__ == "__main__":
    main()